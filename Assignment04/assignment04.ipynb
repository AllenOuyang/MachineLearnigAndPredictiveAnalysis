{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/allenouyang/jupyter/2023Spring ML&PA(MSU)/Assignment04/machine_learning_04_data\" # replace with your own local folder path\n",
    "train = pd.read_csv(os.path.join(data_path,\"train_sample.csv\"))\n",
    "test = pd.read_csv(os.path.join(data_path,\"test_sample.csv\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform 5-fold cross-validation and find the best number of rounds for binary classification using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train.iloc[:,:-1], label=train['class'])\n",
    "params = {'objective': 'binary:logistic', 'eval_metric': 'auc'}\n",
    "cv_results = xgb.cv(params=params, dtrain=dtrain, num_boost_round=1000, nfold=5,\n",
    "                    early_stopping_rounds=10, seed=0, verbose_eval=False)\n",
    "best_num_rounds = cv_results.shape[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a DMatrix object from the training data, sets the parameters for the XGBoost model, and performs 5-fold cross-validation with a maximum of 1000 boosting rounds. The early_stopping_rounds parameter is used to stop boosting early if there is no improvement in performance for 10 rounds. The best number of rounds is determined from the cross-validation results.\n",
    "\n",
    "To fit XGBoost with the best number of rounds and make predictions for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(params=params, dtrain=dtrain, num_boost_round=best_num_rounds)\n",
    "dtest = xgb.DMatrix(test)\n",
    "prediction = bst.predict(dtest)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code trains the XGBoost model with the best number of rounds on the entire training set and makes predictions for the test set.\n",
    "\n",
    "To perform random forest classification with default settings and find the most important feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(train.iloc[:,:-1], train['class'])\n",
    "importances = rf.feature_importances_\n",
    "rf_most_important = np.argsort(importances)[-1] + 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code initializes a random forest classifier with random_state=0, fits it to the training data, and computes the feature importances. The index of the most important feature is determined and saved to rf_most_important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('submission.npz', rf_most_important=rf_most_important, prediction=prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (500,)\n"
     ]
    }
   ],
   "source": [
    "npzfile = np.load('submission.npz')\n",
    "print(npzfile['rf_most_important'],npzfile['prediction'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpa",
   "language": "python",
   "name": "mlpa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
